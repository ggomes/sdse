{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Lab 4 <br><br> Linear regression and Feature selection </center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "In this lab we will use linear regression to predict cancer mortality rates based on data obtained from the American Community Survey of the [U.S. Census Bureau](https://www.census.gov/). The lab has five parts. In part 1 you will load the data and do basic manipulations using [pandas](https://pandas.pydata.org/docs/index.html). Pandas is a Python package that specializes in tabular data. It is widely used in data science and machine learning since the data in these fields are usually structured as a table. Pandas is a very powerful library that is well worth investing some time in. [Here](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) and [here](https://pandas.pydata.org/docs/user_guide/index.html) are resources to learn more.\n",
    "\n",
    "In part 2 you will perform linear regression on the full feature set. In part 3 you will assess the performance of the linear regression model using the coefficient of determination. Then, in part 4 compute confidence intervals for the slope parameters of the linear regression model. Finally, in part 5 you will run the forward and backward stepwise feature selection algorithms and estimate the performance of the resulting model using a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.061182Z",
     "iopub.status.busy": "2025-10-18T16:26:53.060889Z",
     "iopub.status.idle": "2025-10-18T16:26:53.826418Z",
     "shell.execute_reply": "2025-10-18T16:26:53.826052Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from resources.hashutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1:  Loading and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.1 Load the data into a pandas DataFrame\n",
    "\n",
    "Use [pd.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) to load the data from `cancerdata.csv`.\n",
    "\n",
    "You can obtain information about the data using these DataFrame methods and attributes:\n",
    "+ [`data0.head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html): displays the first 5 rows of the DataFrame.\n",
    "+ [`data0.tail()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html): displays the last 5 rows of the DataFrame.\n",
    "+ [`data0.shape`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html): a tuple with the number of rows and of columns in the DataFrame.\n",
    "+ [`data0.columns`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html): the column headers.\n",
    "+ [`data0.index`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html): a unique identifier for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.828055Z",
     "iopub.status.busy": "2025-10-18T16:26:53.827834Z",
     "iopub.status.idle": "2025-10-18T16:26:53.839044Z",
     "shell.execute_reply": "2025-10-18T16:26:53.838675Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data0 = ...  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.2 Inspect columns\n",
    "\n",
    "Run `data0.info()` and note:\n",
    " a) which inputs are non-numerical (Dtype=object), and\n",
    " b) which inputs have null entries (Non-Null Count<3047).\n",
    "\n",
    "Store the names ('Column' entry) of the non-numerical inputs in a [set](https://www.w3schools.com/python/python_sets.asp) called `non_numerical_inputs`. Store the names of inputs with null entries in a set called `null_entry_inputs`.\n",
    "\n",
    "**Note**: If not all of the rows of `data0.info()` are displayed, you'll probably have this message at the bottom:\n",
    "\n",
    "*``Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...''*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.865420Z",
     "iopub.status.busy": "2025-10-18T16:26:53.865137Z",
     "iopub.status.idle": "2025-10-18T16:26:53.873907Z",
     "shell.execute_reply": "2025-10-18T16:26:53.873515Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data0.info()\n",
    "non_numerical_inputs = {...,...}      # TODO\n",
    "null_entry_inputs = {...,...,...}     # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.3 Discard non-numerical columns\n",
    "\n",
    "Remove the two columns with non-numeric data.\n",
    "\n",
    "Hints:\n",
    "+ `data0.dtypes` lists the data types for each column.\n",
    "+ You can construct a boolean mask for non-numeric columns with `data0.dtypes=='object'`.\n",
    "+ Use that mask to index `data.columns`\n",
    "+ Use [`data0.drop`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) to remove the selected columns.\n",
    "+ Save the result as `data1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.884223Z",
     "iopub.status.busy": "2025-10-18T16:26:53.883847Z",
     "iopub.status.idle": "2025-10-18T16:26:53.888138Z",
     "shell.execute_reply": "2025-10-18T16:26:53.887799Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ind = ...               # TODO\n",
    "drop_cols = ...         # TODO\n",
    "data1 = data0.drop(...)       # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1p3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.4 Discard columns where more than 10% of values are nan\n",
    "\n",
    "Hints:\n",
    "+ [`.dropna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
    "+ Use `axis=1` to drop columns (as opposed to `axis=1` for rows.\n",
    "+ Use the `thresh` argument. The condition for dropping a column is that it has less than `round(0.9*data1.shape[0])` non-nans.\n",
    "+ Save the result as `data2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.900468Z",
     "iopub.status.busy": "2025-10-18T16:26:53.900330Z",
     "iopub.status.idle": "2025-10-18T16:26:53.903917Z",
     "shell.execute_reply": "2025-10-18T16:26:53.903659Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "thresh = ...                # TODO\n",
    "data2 = data1.dropna(...)     # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1p4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.5 Drop all rows that contain one or more nans.\n",
    "\n",
    "Save the result as `data3`.\n",
    "\n",
    "Hint: You can again use `dropna` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.918559Z",
     "iopub.status.busy": "2025-10-18T16:26:53.918432Z",
     "iopub.status.idle": "2025-10-18T16:26:53.921562Z",
     "shell.execute_reply": "2025-10-18T16:26:53.921296Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data3 = ...      # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1p5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.6 Inspect correlations\n",
    "\n",
    "Next we'll look at the sample correlation coefficients between each of the inputs and the output (a.k.a. target variable) `target_deathrate`. This is a quick way to check which of the inputs may be most useful to include in a model. Correlations only provide an initial guess, however. Remember that the correlation coefficient only measures the linear relationship between variables. That's perfect when the model is linear (as in this lab activity), but less useful for nonlinear models.\n",
    "\n",
    "1) Use `data3.corr()` to build the correlations matrix.\n",
    "2) Inspect the column (or row) corresponding to `target_deathrate`.\n",
    "3) Rank (i.e. sort) the inputs from most to least correlated with the output. This ranking is in terms of the absolute value of the sample correlation coefficient.\n",
    "4) Save the top 5 correlated inputs to `top_5_sort`. `top_5_sort` should be a numpy array with shape `(5,)`.\n",
    "\n",
    "Hints:\n",
    "+ [`abs`](https://pandas.pydata.org/docs/reference/api/pandas.Series.abs.html)\n",
    "+ [`sort_values`](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html)\n",
    "+ [`to_numpy`](https://pandas.pydata.org/docs/reference/api/pandas.Series.to_numpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.929494Z",
     "iopub.status.busy": "2025-10-18T16:26:53.929325Z",
     "iopub.status.idle": "2025-10-18T16:26:53.935606Z",
     "shell.execute_reply": "2025-10-18T16:26:53.935252Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "C = ...         # TODO\n",
    "\n",
    "# vector correlations between the inputs and target_deathrate\n",
    "corr_target = ...         # TODO\n",
    "\n",
    "# sorted corr_target_sort\n",
    "corr_target_sort = ...         # TODO\n",
    "\n",
    "# top 5 correlations with target_deathrate\n",
    "top_5_sort = ...         # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1p6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.7 Scatter plot\n",
    "\n",
    "Make a scatter plot of the data with the most correlated input along the x axis, and the target along the y axis.\n",
    "\n",
    "Hint: You can use the plotting function attached to the DataFrame: [data3.plot(kind='scatter',x=..., y=...)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:53.943533Z",
     "iopub.status.busy": "2025-10-18T16:26:53.943265Z",
     "iopub.status.idle": "2025-10-18T16:26:54.030591Z",
     "shell.execute_reply": "2025-10-18T16:26:54.030228Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data3.plot(kind='scatter',x=...,y=...)   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Estimate the parameters of a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2.1 Extract `X` and `Y` from `data3`\n",
    "\n",
    "The next cell extracts the `X` and `Y` matrices from `data3` and constructs a list of `inputs`. Define the number of samples `N` and the total number of inputs `D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.032300Z",
     "iopub.status.busy": "2025-10-18T16:26:54.032024Z",
     "iopub.status.idle": "2025-10-18T16:26:54.035337Z",
     "shell.execute_reply": "2025-10-18T16:26:54.035114Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X = data3.drop(columns='target_deathrate').values\n",
    "all_inputs = data3.columns.values\n",
    "all_inputs = all_inputs[all_inputs!='target_deathrate']\n",
    "Y = data3['target_deathrate'].values\n",
    "\n",
    "N = ...\n",
    "D = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2.2 Construct $\\mathbb{X}$ defined in Eq. (6.112) of the reader\n",
    "\n",
    "Implement the formula and store the result in the variable name `Xe`.\n",
    "\n",
    "**Hint**: \n",
    "+ [np.hstack](https://numpy.org/doc/2.1/reference/generated/numpy.hstack.html)\n",
    "+ [np.ones](https://numpy.org/doc/2.3/reference/generated/numpy.ones.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.046890Z",
     "iopub.status.busy": "2025-10-18T16:26:54.046685Z",
     "iopub.status.idle": "2025-10-18T16:26:54.049216Z",
     "shell.execute_reply": "2025-10-18T16:26:54.048967Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Xe = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2.3 Find the solution $\\underline{\\hat\\theta}$ of linear regression using Eq. (6.121) of the reader.\n",
    "\n",
    "Implement the formula and store the result in the variable name `thetahat`.\n",
    "\n",
    "Hint: \n",
    "+ [np.linalg.inv](https://numpy.org/doc/2.3/reference/generated/numpy.linalg.inv.html)\n",
    "+ Matrix multiplication in NumPy can be achieved with the `@` operator or with [np.matmul](https://numpy.org/doc/2.3/reference/generated/numpy.matmul.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.058876Z",
     "iopub.status.busy": "2025-10-18T16:26:54.058660Z",
     "iopub.status.idle": "2025-10-18T16:26:54.061615Z",
     "shell.execute_reply": "2025-10-18T16:26:54.061297Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "thetahat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2p3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2.4 Extract $\\hat\\theta_0$ and $\\underline{\\hat\\theta}_1$ from $\\underline{\\hat\\theta}$ as per Eq. (6.113) of the reader.\n",
    "\n",
    "Eq. (6.113) shows the arrangement of candidate parameters $\\theta_0$ and $\\underline{\\theta}_1$ into a candidate parameter vector $\\underline{\\theta}$. The same arrangement applies to the parameter estimates $\\hat\\theta_0$ and $\\underline{\\hat\\theta}_1$. Unpack $\\hat\\theta$ into $\\hat\\theta_0$ and $\\underline{\\hat\\theta}_1$, and save these respectively to variables `theta0hat` and `theta1hat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.070909Z",
     "iopub.status.busy": "2025-10-18T16:26:54.070781Z",
     "iopub.status.idle": "2025-10-18T16:26:54.073544Z",
     "shell.execute_reply": "2025-10-18T16:26:54.073247Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "theta0hat = ...\n",
    "theta1hat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2p4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Part 3: Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3.1 Compute predictions for each of the training samples using Eq. (6.111)\n",
    "\n",
    "Implement the formula and store the result in the variable name `Yhat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.095698Z",
     "iopub.status.busy": "2025-10-18T16:26:54.095567Z",
     "iopub.status.idle": "2025-10-18T16:26:54.099801Z",
     "shell.execute_reply": "2025-10-18T16:26:54.099492Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Yhat = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3.2 Compute the coefficient of determination using Eq. (5.21). \n",
    "\n",
    "Implement the formula and store the result in the variable name `R2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.109545Z",
     "iopub.status.busy": "2025-10-18T16:26:54.109322Z",
     "iopub.status.idle": "2025-10-18T16:26:54.112293Z",
     "shell.execute_reply": "2025-10-18T16:26:54.112009Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "R2 = ...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Parameter uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4.1 Compute the average input value using Eq. (6.117) of the reader\n",
    "\n",
    "Implement the formula and store the result in the variable name `muhatX`.\n",
    "\n",
    "Hint: You can use the `axis` argument of [np.mean](https://numpy.org/doc/2.2/reference/generated/numpy.mean.html) to take an average across all samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.120982Z",
     "iopub.status.busy": "2025-10-18T16:26:54.120852Z",
     "iopub.status.idle": "2025-10-18T16:26:54.123547Z",
     "shell.execute_reply": "2025-10-18T16:26:54.123210Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "muhatX = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.2 Compute the centered inputs using Eq. (6.129) \n",
    "\n",
    "\n",
    "Hint: \n",
    "+ The formula for `Xc` has $\\mathbf{1}_N\\hat\\mu_X$. The broadcasting rules of numpy make multiplying $\\hat\\mu_X$ by $\\mathbf{1}_N$ unnecessary.\n",
    "+ Check that the column-wise means of `Xc` equal zero (to machine precision). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.132579Z",
     "iopub.status.busy": "2025-10-18T16:26:54.132315Z",
     "iopub.status.idle": "2025-10-18T16:26:54.134927Z",
     "shell.execute_reply": "2025-10-18T16:26:54.134645Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Xc = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.3 Compute $\\hat\\sigma^2$, an unbiased estimate $\\sigma^2$\n",
    "\n",
    "Equation (6.105) of the reader gives the formula for estimating the variance of the measurement noise $\\mathcal{E}$ when there is only one input ($D=1$). \n",
    "\n",
    "$$\\hat\\sigma^2 = \\frac{1}{N-2} \\sum_{i=1}^{N}(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "The generalization of this formula to the case of $D$ inputs is,\n",
    "\n",
    "$$\\hat\\sigma^2 = \\frac{1}{N-D-1} \\sum_{i=1}^{N}(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "Implement this formula and assign the result to the variable `sigmahat2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.145461Z",
     "iopub.status.busy": "2025-10-18T16:26:54.145270Z",
     "iopub.status.idle": "2025-10-18T16:26:54.148090Z",
     "shell.execute_reply": "2025-10-18T16:26:54.147803Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "sigmahat2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.4 Compute the variances of the slope parameters\n",
    "\n",
    "The slope parameters are contained in the array $\\underline{\\hat\\theta}_1$. Compute their covariance matrix using Eq. (6.165) of the reader. In this equation you should replace the true noise level $\\sigma^2$ with the estimate $\\hat\\sigma^2$ calculated in part 4.3. Save this matrix to the variable `CovThetaHat1`. Then extract the diagonal entries of this matrix, which correspond to the variances of each of the slope parameters. Save this to a 1D array called `varThetaHat1` \n",
    "\n",
    "**Hint**: [`np.diag`](https://numpy.org/doc/stable/reference/generated/numpy.diag.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.156750Z",
     "iopub.status.busy": "2025-10-18T16:26:54.156622Z",
     "iopub.status.idle": "2025-10-18T16:26:54.159440Z",
     "shell.execute_reply": "2025-10-18T16:26:54.159149Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "CovThetaHat1 = ...\n",
    "varThetaHat1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.5 Compute the radiuses of confidence intervals on the slope parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Having the variances of each of the slope parameters in `varThetaHat1`, and assuming that the output measurement noise is Gaussian, we can apply our generic formula from lecture for the radius of a confidence interval. This gives the following for the radius of a confidence interval for $\\theta_d$:\n",
    "$$\\rho_d =\\sqrt{v_d} \\left| F^{-1}_{\\mathcal{N}}\\left( \\frac{1-\\gamma}{2}\\right)\\right| $$\n",
    "Here $v_d$ is the variance of the $d$'th slope parameter, i.e. `varThetaHat1[d]`.\n",
    "\n",
    "Compute the radiuses of 95\\% confidence intervals for each of the slope parameters. Store these in the array `rho`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.171949Z",
     "iopub.status.busy": "2025-10-18T16:26:54.171827Z",
     "iopub.status.idle": "2025-10-18T16:26:54.175508Z",
     "shell.execute_reply": "2025-10-18T16:26:54.175197Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "\n",
    "rho = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4.6 Tag as \"significant\" those parameters whose confidence interval does not include zero.\n",
    "\n",
    "Create a 1D NumPy boolean array of the same size as `theta1hat` called `significant`. The $d$'th entry of `significant` should be `True` if the 95\\% confidence interval for the corresponding slope parameter **does not** include 0, and `False` otherwise. In other words, an input is considered significant if its slope parameter is non-zero with 95\\% confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.184376Z",
     "iopub.status.busy": "2025-10-18T16:26:54.184109Z",
     "iopub.status.idle": "2025-10-18T16:26:54.186792Z",
     "shell.execute_reply": "2025-10-18T16:26:54.186512Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "significant = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Parameters table (done already)\n",
    "Make a DataFrame with one row for each input. The index of the table should be the input names. The columns should be:\n",
    "+ `slope`: the estimates of the slope parameter associated with the input. \n",
    "+ `slope stddev`: the standard deviation of the slope parameter.\n",
    "+ `significant`: whether the input is significant according to part 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.195371Z",
     "iopub.status.busy": "2025-10-18T16:26:54.195249Z",
     "iopub.status.idle": "2025-10-18T16:26:54.203542Z",
     "shell.execute_reply": "2025-10-18T16:26:54.203259Z"
    }
   },
   "outputs": [],
   "source": [
    "params_table = pd.DataFrame(index=all_inputs,\n",
    "             data={'slope':theta1hat,\n",
    "                   'slope stddev':np.sqrt(varThetaHat1),\n",
    "                   'significant':significant})\n",
    "\n",
    "params_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.8 Build an array of significant inputs\n",
    "\n",
    "Extract the names of the significant inputs from `params_table` using the `significant` array from part 4.7.\n",
    "\n",
    "Store these significant input names as `significant_inputs`. \n",
    "\n",
    "`significant_inputs` should be a NumPy array with shape `(15,)`.\n",
    "\n",
    "Here's one way you can do this that doesn't require a \"for\" loop:\n",
    "1. Use the `significant` column to select the rows of the table corresponding to significant inputs. \n",
    "2. Use `.index` to obtain the names of the inputs for those rows. \n",
    "3. Use `.to_numpy()` to convert the result to a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.204997Z",
     "iopub.status.busy": "2025-10-18T16:26:54.204730Z",
     "iopub.status.idle": "2025-10-18T16:26:54.208427Z",
     "shell.execute_reply": "2025-10-18T16:26:54.208145Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "significant_inputs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Create a new table with significant inputs only (done already)\n",
    "\n",
    "This table is called `data` and the target variable is now called `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.219435Z",
     "iopub.status.busy": "2025-10-18T16:26:54.219183Z",
     "iopub.status.idle": "2025-10-18T16:26:54.230401Z",
     "shell.execute_reply": "2025-10-18T16:26:54.230141Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data3[significant_inputs].copy()\n",
    "data['Y'] = data3['target_deathrate']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Feature subset selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Split `data` into training, validation, and testing datasets (done already)\n",
    "\n",
    "We will use 70% of the data for training, 15% for validation, and 15% for testing.\n",
    "\n",
    "1. Define `Dtrain` as the first `Ntrain` rows of `data`.\n",
    "2. Define `Dvalidate` as the next `Nvalidate` rows of `data`.\n",
    "3. Define `Dtest` as the last `Ntest` rows of `data`.\n",
    "\n",
    "Here we use pandas' [iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) method for selecting the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.231710Z",
     "iopub.status.busy": "2025-10-18T16:26:54.231503Z",
     "iopub.status.idle": "2025-10-18T16:26:54.233846Z",
     "shell.execute_reply": "2025-10-18T16:26:54.233579Z"
    }
   },
   "outputs": [],
   "source": [
    "Ntrain = round(0.7*N)\n",
    "Nvalidate = round(0.15*N)\n",
    "Ntest = N - Ntrain - Nvalidate\n",
    "Ntrain, Nvalidate, Ntest\n",
    "\n",
    "Dtrain = data.iloc[:Ntrain,:]\n",
    "Dvalidate = data.iloc[Ntrain:Ntrain+Nvalidate,:]\n",
    "Dtest = data.iloc[Ntrain+Nvalidate:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 5.2 Linear regression training function\n",
    "\n",
    "Create a function called `train` that receives a list of features `S` and a dataset `Dtrain` and does the following:\n",
    "1. Selects the features `S` from `Dtrain` and stores them in `X`. (done already)\n",
    "2. Selects the target values from `Dtrain` and stores them in `Y`. (done already)\n",
    "3. Performs the linear regression calculations from parts 2.2 and 2.3 (copy your code from those parts into the `train` method)\n",
    "4. Returns the estimated parameter vector `thetahat` containing $\\hat\\theta_0$ and $\\underline{\\hat\\theta}_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.235066Z",
     "iopub.status.busy": "2025-10-18T16:26:54.234900Z",
     "iopub.status.idle": "2025-10-18T16:26:54.239123Z",
     "shell.execute_reply": "2025-10-18T16:26:54.238862Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def train(S, Dtrain):\n",
    "\n",
    "    X = Dtrain[list(S)].values\n",
    "    Y = Dtrain['Y'].values\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # 2.2 Construct $\\mathbb{X}$\n",
    "    Xe = ...\n",
    "\n",
    "    # 2.3 Compute thetahat\n",
    "    thetahat = ...\n",
    "\n",
    "    return thetahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.240101Z",
     "iopub.status.busy": "2025-10-18T16:26:54.239986Z",
     "iopub.status.idle": "2025-10-18T16:26:54.242307Z",
     "shell.execute_reply": "2025-10-18T16:26:54.242066Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Use this cell to test your code\n",
    "\n",
    "thetahat = train(['incidencerate','birthrate'], Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 5.3 Model evaluation function\n",
    "\n",
    "Create a function called `eval` that receives\n",
    "+ `S`... a set of input feature names\n",
    "\n",
    " the linear regression parameters `thetahat`, the corresponding feature names `S`, and a dataset `D`, which may be the validation, the training, or the testing dataset.\n",
    "\n",
    "The function should evaluate the mean squared error (MSE) of the model using this data.\n",
    "\n",
    "The steps are:\n",
    "1. Select the features `S` from `D` and stores them in `X`. (done already)\n",
    "2. Select the target values from `D` and stores them in `Y`. (done already)\n",
    "3. Compute `Yhat`, as in part 3.1.\n",
    "4. Evaluate $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.251509Z",
     "iopub.status.busy": "2025-10-18T16:26:54.251342Z",
     "iopub.status.idle": "2025-10-18T16:26:54.254421Z",
     "shell.execute_reply": "2025-10-18T16:26:54.254195Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def train_eval(S, Dtrain, Deval):\n",
    "\n",
    "    # fix the order of the inputs S by casting it to a list\n",
    "    S = list(S)\n",
    "\n",
    "    # train linear regression (call the training function you already made)\n",
    "    thetahat = ...\n",
    "\n",
    "    # unpack the linear regression coefficients\n",
    "    theta0hat = ...\n",
    "    theta1hat = ...\n",
    "\n",
    "    # unpack the evaluation data\n",
    "    X = Deval[S].values\n",
    "    Y = Deval['Y'].values\n",
    "\n",
    "    # compute predictions for each of the samples (same as part 3.1)\n",
    "    Yhat = ...\n",
    "\n",
    "    # 2.7 Evaluate performance with R2 (same as part 3.2)\n",
    "    R2 = ...\n",
    "    \n",
    "    return R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.255688Z",
     "iopub.status.busy": "2025-10-18T16:26:54.255557Z",
     "iopub.status.idle": "2025-10-18T16:26:54.258132Z",
     "shell.execute_reply": "2025-10-18T16:26:54.257868Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Use this cell to test your code\n",
    "r2 = train_eval(['incidencerate','birthrate'], Dtrain, Dvalidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5p3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Forward feature selection\n",
    "\n",
    "Below is a method that implements the forward feature selection algorithm that was described by your GSI in lab. \n",
    "\n",
    "This part has no deliverables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.267591Z",
     "iopub.status.busy": "2025-10-18T16:26:54.267391Z",
     "iopub.status.idle": "2025-10-18T16:26:54.270854Z",
     "shell.execute_reply": "2025-10-18T16:26:54.270534Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_selection(all_inputs):\n",
    "\n",
    "    # allocate stuff\n",
    "    P = len(all_inputs)                     # ... number of inputs\n",
    "    setF = set(all_inputs)                  # ... fixed set of all inputs\n",
    "    setFk = [set() for i in range(P+1)]     # ... array of best input set at each stage\n",
    "    ellk = np.empty(P+1)             # ... array of best performance at each stage\n",
    "\n",
    "    # initialize\n",
    "    setFk[0] = set()\n",
    "    ellk[0] = train_eval(set(),Dtrain,Dvalidate)\n",
    "\n",
    "    # loop through stages\n",
    "    for k in range(1,P+1):\n",
    "        \n",
    "        # allocate for inner loop \n",
    "        setA = [set() for i in range(P-k+1)]  # ... array of input sets to evaluate\n",
    "        pkappa = np.full(P-k+1,np.inf)        # ... array of performance values\n",
    "\n",
    "        # inner loop: through all remaining inputs to add\n",
    "        for kappa, phip in enumerate(setF-setFk[k-1]):\n",
    "\n",
    "            # add the p-th input (number kappa among remaining inputs)\n",
    "            setA[kappa] = setFk[k-1].union({phip})\n",
    "\n",
    "            # train with the training data, evaluate with validation data\n",
    "            pkappa[kappa] = train_eval(setA[kappa],Dtrain,Dvalidate)\n",
    "\n",
    "        # keep the best set and its performance.\n",
    "        kappastar = pkappa.argmax()\n",
    "        setFk[k] = setA[kappastar]\n",
    "        ellk[k] = pkappa[kappastar]\n",
    "\n",
    "    # keep the best over all stages\n",
    "    kstar = ellk.argmax()\n",
    "    Fstar = setFk[kstar]\n",
    "\n",
    "    # save the best parameters and their performance\n",
    "    ellstar = train_eval(Fstar, Dtrain, Dtest)\n",
    "\n",
    "    return ellk, ellstar, kstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.271877Z",
     "iopub.status.busy": "2025-10-18T16:26:54.271741Z",
     "iopub.status.idle": "2025-10-18T16:26:54.324396Z",
     "shell.execute_reply": "2025-10-18T16:26:54.324037Z"
    }
   },
   "outputs": [],
   "source": [
    "# You can run forward selection on the collection of significant inputs\n",
    "\n",
    "f_ellk, f_ellstar, f_kstar = forward_selection(significant_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 5.5 Backward feature removal\n",
    "\n",
    "Implement backward feature removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.325855Z",
     "iopub.status.busy": "2025-10-18T16:26:54.325703Z",
     "iopub.status.idle": "2025-10-18T16:26:54.330178Z",
     "shell.execute_reply": "2025-10-18T16:26:54.329910Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def backward_removal(all_inputs):\n",
    "\n",
    "    ...\n",
    "\n",
    "    return ellk, ellstar, kstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.331241Z",
     "iopub.status.busy": "2025-10-18T16:26:54.331138Z",
     "iopub.status.idle": "2025-10-18T16:26:54.383133Z",
     "shell.execute_reply": "2025-10-18T16:26:54.382855Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Use this cell to test your code\n",
    "b_ellk, b_ellstar, b_kstar = backward_removal(significant_inputs)\n",
    "\n",
    "b_ellk, b_ellstar, b_kstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5p5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5.6 Run forward and backward selection (done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.539947Z",
     "iopub.status.busy": "2025-10-18T16:26:54.539800Z",
     "iopub.status.idle": "2025-10-18T16:26:54.634740Z",
     "shell.execute_reply": "2025-10-18T16:26:54.634430Z"
    }
   },
   "outputs": [],
   "source": [
    "f_ellk, f_ellstar, f_kstar = forward_selection(significant_inputs)\n",
    "b_ellk, b_ellstar, b_kstar = backward_removal(significant_inputs)\n",
    "P = len(significant_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Plot (done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:26:54.636344Z",
     "iopub.status.busy": "2025-10-18T16:26:54.636198Z",
     "iopub.status.idle": "2025-10-18T16:26:54.855963Z",
     "shell.execute_reply": "2025-10-18T16:26:54.855663Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot forward seleection in blue\n",
    "color = 'blue'\n",
    "plt.plot(range(P+1),f_ellk,'o-',color=color,linewidth=3,label='forward (validation)')\n",
    "plt.plot([f_kstar,f_kstar],[f_ellk[f_kstar],f_ellstar],color=color,linestyle='--',linewidth=2)\n",
    "plt.plot(f_kstar,f_ellstar,'*',color=color,markersize=22,label='forward (test)')\n",
    "\n",
    "# Plot backward removal in orange\n",
    "color = 'darkorange'\n",
    "plt.plot(range(P+1),b_ellk,'o-',color=color,linewidth=2,label='backward (validation)')\n",
    "plt.plot([b_kstar,b_kstar],[b_ellk[b_kstar],b_ellstar],color=color,linestyle=':',linewidth=2)\n",
    "plt.plot(b_kstar,b_ellstar,'*',color=color,markersize=16,label='backward (test)')\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(linestyle=':')\n",
    "plt.xticks(range(16),fontsize=16)\n",
    "plt.xlabel('k (number of inputs included)',fontsize=16)\n",
    "plt.ylabel(r'$R^2$',fontsize=16,rotation=0,labelpad=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Make sure you submit the .zip file to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab4",
   "tests": {
    "q1p2": {
     "name": "q1p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> non_numerical_inputs == {'geography', 'binnedinc'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> null_entry_inputs == {'pctsomecol18_24', 'pctprivatecoveragealone', 'pctemployed16_over'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1p3": {
     "name": "q1p3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> data1.shape[0] > 3000 and data1.shape[0] < 3100\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> data1.shape[1] == 26\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> A = data1.columns.to_numpy().copy()\n>>> A.sort()\n>>> h = [get_hash(a) for a in A]\n>>> h == ['0ad6752935593b398c5b2e03e67956a8', '01915914efcc68fd29e1958648d4ad9a', '6e2ef10ca497cec351147c5548df65b0', 'bd6282c738ee849dcf6df51cbacb6fb6', '9aed79c74c3b56d88a469bd924d5536a', 'f6f19e7962a9cb1519a04973bb9e8767', '019ecaf6b6730586dfbed865d892a780', '426951735326c71c501d00ef63df3e71', '311b38f064bf47006677ad0580e442f8', 'ea892d7d8efd039319033bd345077f3b', '98af7560c20e755217434ab3ef503d00', 'b0b242280111a535759eeaece794e5cf', 'c7f0a021cd78750c0d124f83b0fdb731', '979395d25696c193bd3e11f9b7f625db', '5aa96cfedb0cd72cf87612147fab5aba', '3c2052cb47e7261583fabe6f76b74a64', '1d4775730357445b9b289574d854c3c5', 'f636665ff9d00921e2e0178931e00cf3', '46926b87727f040d06ae16b5f01f858e', 'c096e7dd49576ce7b9be6461f5c3650f', '0941e7200c731e193120b119d5e3be71', '7c85111de502c96aba2feafba12005d4', 'b533d326331997223720398741cb3f93', '9862bc7c6c3f3bf6b5bdd11faf2b18c2', 'eb4ff559f5f2be0b9d8ee50d9532703e', '102fb5f603a205bd350961efb6054b1c']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1p4": {
     "name": "q1p4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> thresh > 2700 and thresh < 2800\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> data2.shape[1] == 24\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(thresh, 4) == '4fd32b31ea0748490ef09f7fe56b8d6f'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> A = data2.columns.to_list()\n>>> A.sort()\n>>> [get_hash(a) for a in A] == ['0ad6752935593b398c5b2e03e67956a8', '01915914efcc68fd29e1958648d4ad9a', '6e2ef10ca497cec351147c5548df65b0', 'bd6282c738ee849dcf6df51cbacb6fb6', '9aed79c74c3b56d88a469bd924d5536a', 'f6f19e7962a9cb1519a04973bb9e8767', '019ecaf6b6730586dfbed865d892a780', '426951735326c71c501d00ef63df3e71', '311b38f064bf47006677ad0580e442f8', 'ea892d7d8efd039319033bd345077f3b', '98af7560c20e755217434ab3ef503d00', 'b0b242280111a535759eeaece794e5cf', 'c7f0a021cd78750c0d124f83b0fdb731', '979395d25696c193bd3e11f9b7f625db', '5aa96cfedb0cd72cf87612147fab5aba', '3c2052cb47e7261583fabe6f76b74a64', '1d4775730357445b9b289574d854c3c5', '46926b87727f040d06ae16b5f01f858e', 'c096e7dd49576ce7b9be6461f5c3650f', '7c85111de502c96aba2feafba12005d4', 'b533d326331997223720398741cb3f93', '9862bc7c6c3f3bf6b5bdd11faf2b18c2', 'eb4ff559f5f2be0b9d8ee50d9532703e', '102fb5f603a205bd350961efb6054b1c']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1p5": {
     "name": "q1p5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> data3.shape == (2895, 24)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(data3.index, 4) == '5e33b407227c7dda3c52b4b51485be0e'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1p6": {
     "name": "q1p6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> corr_target_sort.shape == (24,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> A = top_5_sort.copy()\n>>> A.sort()\n>>> h = [get_hash(a) for a in A]\n>>> h == ['6e2ef10ca497cec351147c5548df65b0', '9aed79c74c3b56d88a469bd924d5536a', '426951735326c71c501d00ef63df3e71', 'c096e7dd49576ce7b9be6461f5c3650f', 'eb4ff559f5f2be0b9d8ee50d9532703e']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2p1": {
     "name": "q2p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N > 1000 and N < 3000 and (P > 10) and (P < 30) and (all_inputs.shape[0] == 23) and (Y.shape[0] == 2895) and (X.shape == (2895, 23))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(N, 4) == 'c455fdadcc5232e7e119979863ef3848'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(P, 2) == '6bc071ec71e51c704acd13cdc898fd93'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2p2": {
     "name": "q2p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xe.shape == (2895, 24)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(Xe, 4) == '794bba9d89c4411be99153fc08634c78'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2p3": {
     "name": "q2p3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> thetahat.shape == (24,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(thetahat, 4) == '20d4f19fa78ee48a1f7184205af8286b'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2p4": {
     "name": "q2p4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(theta0hat > 150 and theta0hat < 200)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> theta1hat.shape == (23,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(min(theta1hat) > -2 and max(theta1hat) < 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(theta0hat, 4) == 'aa75626390499106698bbc42e492af3a'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> get_hash(theta1hat, 4) == '598d817c35ff8dd43907a6470ed5ebfa'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3p1": {
     "name": "q3p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Yhat.shape == (2895,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(Yhat, 4) == '1f8b043cdf729e97b6f8b8592bed2336'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3p2": {
     "name": "q3p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(R2 > 0.5 and R2 < 0.6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(R2, 4) == 'f71f388290a0e65c50c79a675b8f1811'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p1": {
     "name": "q4p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> muhatX.shape == (23,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(muhatX, 4) == 'd3b9e3451b30c05adf3eae1beb231ce9'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p2": {
     "name": "q4p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xc.shape == (2895, 23)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(Xc, 3) == '02f312181e07841edaa62e20c1c346c7'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p3": {
     "name": "q4p3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(sigmahat2 > 300 and sigmahat2 < 400)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(sigmahat2, 4) == 'd4dbd5f2e721125a067d995f84a394f0'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p4": {
     "name": "q4p4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> CovThetaHat1.shape == (23, 23)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> varThetaHat1.shape[0] == 23\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(varThetaHat1, 4) == '53ec6c6ab5e14697ed4eed1de7877090'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p5": {
     "name": "q4p5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> rho.shape == (23,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(rho, 4) == '68e52ca65ae047457e67cb4d8d3b53d8'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p6": {
     "name": "q4p6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.sum(significant) == 15)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> get_hash(rho, 4) == '68e52ca65ae047457e67cb4d8d3b53d8'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p8": {
     "name": "q4p8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(significant_inputs) == np.ndarray\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> significant_inputs.shape == (15,)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> A = significant_inputs.copy()\n>>> A.sort()\n>>> [get_hash(a) for a in A] == ['01915914efcc68fd29e1958648d4ad9a', '6e2ef10ca497cec351147c5548df65b0', '426951735326c71c501d00ef63df3e71', 'ea892d7d8efd039319033bd345077f3b', '98af7560c20e755217434ab3ef503d00', 'b0b242280111a535759eeaece794e5cf', 'c7f0a021cd78750c0d124f83b0fdb731', '979395d25696c193bd3e11f9b7f625db', '5aa96cfedb0cd72cf87612147fab5aba', '3c2052cb47e7261583fabe6f76b74a64', '1d4775730357445b9b289574d854c3c5', '46926b87727f040d06ae16b5f01f858e', 'c096e7dd49576ce7b9be6461f5c3650f', 'b533d326331997223720398741cb3f93', '9862bc7c6c3f3bf6b5bdd11faf2b18c2']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5p2": {
     "name": "q5p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> thetahat = train(['incidencerate', 'birthrate'], Dtrain)\n>>> bool(np.all(np.isclose(thetahat, [92.08, 0.196, -0.245], atol=0.01)))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> thetahat = train(['pctnohs18_24', 'pcths18_24', 'pcths25_over'], Dtrain)\n>>> get_hash(thetahat, 4) == '1a6cfc8fc80de11991203ec4858901f6'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 4
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5p3": {
     "name": "q5p3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> r2 = train_eval(['incidencerate', 'birthrate'], Dtrain, Dtrain)\n>>> bool(np.isclose(r2, 0.158, atol=0.01))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> r2 = train_eval(['pctnohs18_24', 'pcths18_24', 'pcths25_over'], Dtrain, Dtrain)\n>>> get_hash(r2, 4) == '231a369a26afc8f32767ddd9f7d18ee9'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5p5": {
     "name": "q5p5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> b_ellk, b_ellstar, b_kstar = backward_removal(significant_inputs)\n>>> b_ellk.shape == (16,) and bool(b_ellstar > 0.3 and b_ellstar < 0.5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> b_ellk, b_ellstar, b_kstar = backward_removal(significant_inputs)\n>>> get_hash(b_ellstar, 4) == '72029615b5043c216ba3f757db9636b1'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> b_ellk, b_ellstar, b_kstar = backward_removal(significant_inputs)\n>>> get_hash(b_kstar, 2) == '02ad845d2f8ac57a5c265ea083b2169b'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
